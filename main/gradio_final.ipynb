{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr # for user interface\n",
    "import json # for retrieving json files from website to get price history\n",
    "import urllib.parse # encoding skin names to so it can be fetched through url \n",
    "import matplotlib.pyplot as plt # visualization \n",
    "import ast  \n",
    "import requests # for web scrapping\n",
    "import seaborn as sns # also for visualization\n",
    "import pandas as pd # data framing processed data from json so that it can be plotted\n",
    "from bs4 import BeautifulSoup # for web scrapping \n",
    "import os \n",
    "import random\n",
    "\n",
    "## All for predicting model\n",
    "import time\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler # to normalize data within a range\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error # to be used to count MAE\n",
    "import optuna\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
    "\n",
    "set_seeds(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- load_skins() = Load skins from skins.txt file that was webscrapped from csgoskins.gg. This works from loading the items with format like ('Five-SeveN | Copper Galaxy', True, False) where the first boolean value is the modifier for stattrak and the second for souvenir. We also add the weapon_conditions for each weapons through a nested for loop. \n",
    "- search_list() = Makes a list of tuples to ease the searching process. \n",
    "- load_cases() = Loads cases from cases.txt file that was also webscrapped from csgoskins.gg. The logic is the same as load_skins(|)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "weapon_conditions = [\n",
    "    \"(Factory New)\", \"(Minimal Wear)\", \"(Field-Tested)\", \"(Well-Worn)\", \"(Battle-Scarred)\"\n",
    "]\n",
    "\n",
    "wear = [\n",
    "    \"Factory New\", \"Minimal Wear\", \"Field-Tested\", \"Well-Worn\", \"Battle-Scarred\"\n",
    "]\n",
    "\n",
    "def load_skins():\n",
    "    with open(\"skins.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        skins = [ast.literal_eval(line.strip()) for line in file.readlines()]  \n",
    "\n",
    "    processed_skins = []\n",
    "    for skin, is_stattrak, is_souvenir in skins:\n",
    "        processed_skins.append(skin)  \n",
    "\n",
    "        if is_stattrak:\n",
    "            processed_skins.append(f\"StatTrak {skin}\")\n",
    "\n",
    "        if is_souvenir:\n",
    "            processed_skins.append(f\"Souvenir {skin}\")\n",
    "\n",
    "    with_wear = []\n",
    "    for skin in processed_skins:\n",
    "        for conditions in weapon_conditions:\n",
    "            with_wear.append(f\"{skin} {conditions}\")\n",
    "\n",
    "    return with_wear\n",
    "\n",
    "def search_list():\n",
    "    with open(\"skins.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        skins = [ast.literal_eval(line.strip()) for line in file.readlines()]  \n",
    "\n",
    "    separated_data = []\n",
    "    for name, val1, val2 in skins:\n",
    "        parts = name.split(\" | \")\n",
    "        \n",
    "        if len(parts) == 2:  \n",
    "            weapon, skin = parts\n",
    "        else:\n",
    "            weapon, skin = name, \"Unknown\"  \n",
    "        weapon = weapon.replace(\"★\", \"\")\n",
    "        separated_data.append((weapon.strip(), skin.strip(), val1, val2))\n",
    "\n",
    "    search_processed_skins = []\n",
    "    for skins in separated_data:\n",
    "        for w in wear:\n",
    "                search_processed_skins.append((skins[0], skins[1], \"Base\", w))\n",
    "\n",
    "        if skins[2]:\n",
    "            for w in wear:\n",
    "                search_processed_skins.append((skins[0], skins[1], \"StatTrak\", w))\n",
    "        elif skins[3]:\n",
    "            for w in wear:\n",
    "                search_processed_skins.append((skins[0], skins[1], \"Souvenir\", w))\n",
    "\n",
    "    return search_processed_skins\n",
    "\n",
    "def load_cases():\n",
    "    with open(\"case.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "        cases = [line.strip() for line in file.readlines()]\n",
    "    return cases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching Functions and URL Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- find_skin(sr_format, url_format, wep, s, w, m)\n",
    "    - sr_format: result value from the search_list()\n",
    "    - url_format: result value from the load_skin()\n",
    "    - wep: name of the weapon \n",
    "    - s: name of the skin \n",
    "    - w: wear of the skin \n",
    "    - m: modifier of the skin(stattrak/souvenir)\n",
    "- find_skin(): Works by matching the values given through the parameters with the list of tuples made through search_list(). Matched through their indexes. \n",
    "- find_case(c_data, name): Applies a simpler logic where it takes the data loaded from load_cases() function which is used in the c_data parameter. The name is also given to the function to match it with existing data. \n",
    "- create_url(item): Creates the link to the site containing the price history of an item in the steam market. The json will be downloaded in another phase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_skin(sr_format, url_format, wep,s,w,m):\n",
    "    input_weapon = wep.lower()\n",
    "    input_skin = s.lower() \n",
    "    input_wear = w.lower()\n",
    "    input_modifier = m.lower()\n",
    "    i = 0\n",
    "    for items in sr_format:\n",
    "        weapon = items[0].lower()\n",
    "        skin = items[1].lower()\n",
    "        modifier = items[2].lower()\n",
    "        wear = items[3].lower()\n",
    "        #print(skin,modifier,wear)\n",
    "        if skin == input_skin and modifier == input_modifier and wear == input_wear and weapon == input_weapon:               \n",
    "            print(f\"Item Found in index : {i}\")\n",
    "            print(weapon, modifier, skin, wear)\n",
    "            return url_format[i]\n",
    "        i = i + 1\n",
    "    return None \n",
    "\n",
    "def find_case(c_data, name):\n",
    "    for cases in c_data:\n",
    "        if cases.lower() == name.lower():\n",
    "            return cases \n",
    "\n",
    "def create_url(item):\n",
    "    url_format_base = \"http://steamcommunity.com/market/pricehistory/?appid=730&market_hash_name=\"\n",
    "    formatted = url_format_base+urllib.parse.quote(item, safe=\"★\")\n",
    "    return formatted.replace(\"%E2%98%85\", \"★\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get JSON\n",
    "- get_json(url, file_name): just like its name says, it takes in the url made from create_url and gets the json from that site. It will be saved as the provided name through file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this also has the necessary cookies required to fetch the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: For this step, it is important to have a steam account because without a steam account, you cannot fetch the price history of the item. The cookies are the ones that allows us to fetch the price history data of an item. These cookies can change once in a while so it is possible that the cookies written right now does not work. To get the cookies, you need to inspect the page where steam is logged in at and go to applications and find the sessionid and steamLoginSecure values to ensure that this part can run. Use the temporary account and replace cookie values with the logged in account. Inspect it on https://steamcommunity.com/market/ and make sure you are logged in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Temporary Steam Account: \n",
    "- Username: dia_project_2025\n",
    "- Pass: Project2025\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = { \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    \"Referer\": \"https://steamcommunity.com\",\n",
    "}\n",
    "# if it doesn't work, try another cookie \n",
    "cookies = { # make sure to censor in github\n",
    "    \"sessionid\": \"8aef10bfacdf994fdcf987c4\",\n",
    "    \"steamLoginSecure\": \"76561199837440278%7C%7CeyAidHlwIjogIkpXVCIsICJhbGciOiAiRWREU0EiIH0.eyAiaXNzIjogInI6MDAwN18yNjIwNkQxMV9FNkIwRCIsICJzdWIiOiAiNzY1NjExOTk4Mzc0NDAyNzgiLCAiYXVkIjogWyAid2ViOmNvbW11bml0eSIgXSwgImV4cCI6IDE3NDQ5MDg5NTgsICJuYmYiOiAxNzM2MTgwODc1LCAiaWF0IjogMTc0NDgyMDg3NSwgImp0aSI6ICIwMDAxXzI2Mjg3RjIxX0FBQTFBIiwgIm9hdCI6IDE3NDQ3MzA3NDAsICJydF9leHAiOiAxNzYzMDI2ODQ2LCAicGVyIjogMCwgImlwX3N1YmplY3QiOiAiMjAzLjIxNy4xMzEuMTUiLCAiaXBfY29uZmlybWVyIjogIjIwMy4yMTcuMTMxLjE1IiB9.DVYzvDMKB6fjPgUq0arsqoOOc9M1Vj6aoWqhEy2tFwPgJUFwoSf1_rqK0MU171msJnAodRTz75Nllo-39LHzCw\",\n",
    "}\n",
    "\n",
    "def get_json(url, file_name):\n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, cookies=cookies)\n",
    "        if response.status_code == 400:\n",
    "            print(f\"400 Bad Request for {url}: {response.text}\") \n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        filename = f\"{file_name}.json\"  \n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "        print(f\"Saved JSON as {filename} in the root directory.\")\n",
    "        return True  \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return False  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Item Image\n",
    "- This function is quite simple, you put in the name of the file and go to the listing page and then scrape the image from the site, download it to the same folder and then display it with gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_item_image(item, filename=\"item.jpg\"):\n",
    "    base_link = \"https://steamcommunity.com/market/listings/730/\"\n",
    "    formatted = base_link + urllib.parse.quote(item, safe=\"★\").replace(\"%E2%98%85\", \"★\")\n",
    "\n",
    "    print(formatted)\n",
    "\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    response = requests.get(formatted, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    image_div = soup.find(\"div\", class_=\"market_listing_largeimage\")\n",
    "    if not image_div:\n",
    "        return \"Div not found.\"\n",
    "\n",
    "    img_tag = image_div.find(\"img\", {\"src\": True})\n",
    "    if not img_tag:\n",
    "        return \"Image not found.\"\n",
    "\n",
    "    image_url = img_tag[\"src\"]\n",
    "    img_response = requests.get(image_url, headers=headers)\n",
    "\n",
    "    if img_response.status_code == 200:\n",
    "        os.makedirs(\"images\", exist_ok=True)\n",
    "        \n",
    "        file_path = os.path.join(\"images\", filename)\n",
    "        with open(file_path, \"wb\") as file:\n",
    "            file.write(img_response.content)\n",
    "        \n",
    "        return file_path  \n",
    "    else:\n",
    "        return \"Failed to download image.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Function to be used for Prediction\n",
    "- preprocess_data(file_path): Remove duplicates dates, taking the average price, and set proper date index.\n",
    "- create_sequences(): Prepares time series data for machine learning models, particularly for sequential models like LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(file_path):\n",
    "    \n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        data = json.load(file) # Load the file\n",
    "    \n",
    "    df = pd.DataFrame(data['prices'], columns=['Date', 'Price', 'Value']) # Turns the json file into a dataframe\n",
    "    df['Price'] = df['Price'].astype(float) # Make sure that price is a float type\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%b %d %Y %H: +0', errors='coerce') # Make sures that the date is formated correctly\n",
    "    \n",
    "    # Group by date, average the price with the similar dates\n",
    "    df_grouped = df.groupby(df['Date'].dt.date)['Price'].max().reset_index()\n",
    "    df_grouped.rename(columns={'Date': 'Date', 'Price': 'Price'}, inplace=True)\n",
    "    \n",
    "    # Set index to date\n",
    "    df_grouped['Date'] = pd.to_datetime(df_grouped['Date'])\n",
    "    df_grouped.set_index('Date', inplace=True)\n",
    "    \n",
    "    return df_grouped\n",
    "\n",
    "def create_sequences(data, seq_length=30):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Price Prediction | XGBoost\n",
    "- Predict prices using XGBoost model and plot actual vs predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_price_xgboost(name):\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "\n",
    "        # Load and preprocess data\n",
    "        df = preprocess_data('item.json')\n",
    "        df = df.asfreq('D').interpolate()\n",
    "\n",
    "        # Scale the 'Price' column\n",
    "        scaler = MinMaxScaler()\n",
    "        df['Scaled_Price'] = scaler.fit_transform(df[['Price']])\n",
    "\n",
    "        # Split into training and test sets\n",
    "        train_size = len(df) - 30\n",
    "        train_data = df['Scaled_Price'].iloc[:train_size].values\n",
    "        test_data = df['Scaled_Price'].iloc[train_size:].values\n",
    "\n",
    "        # Prepare sequences\n",
    "        seq_length = 30\n",
    "        X_full, y_full = create_sequences(train_data, seq_length)\n",
    "\n",
    "        # Split for tuning (80% train, 20% validation)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_full, y_full, test_size=0.2, shuffle=False)\n",
    "\n",
    "        X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "        X_val = X_val.reshape(X_val.shape[0], -1)\n",
    "\n",
    "        def objective(trial):\n",
    "            params = {\n",
    "                'objective': 'reg:squarederror',\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "                'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "                'n_estimators': trial.suggest_int('n_estimators', 50, 300),\n",
    "            }\n",
    "            model = xgb.XGBRegressor(**params)\n",
    "            model.fit(X_train, y_train)\n",
    "            preds = model.predict(X_val)\n",
    "            mse = mean_squared_error(y_val, preds)\n",
    "            return mse\n",
    "\n",
    "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=100)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        model = xgb.XGBRegressor(objective='reg:squarederror', **best_params)\n",
    "\n",
    "        X_full = X_full.reshape(X_full.shape[0], -1)\n",
    "        model.fit(X_full, y_full)\n",
    "\n",
    "        # Prepare final test data\n",
    "        X_test, y_test = create_sequences(np.concatenate([train_data[-seq_length:], test_data]), seq_length)\n",
    "        X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "        # Predict (in scaled space)\n",
    "        scaled_predictions = model.predict(X_test)\n",
    "\n",
    "        # Inverse transform predictions and actuals\n",
    "        predictions = scaler.inverse_transform(scaled_predictions.reshape(-1, 1)).flatten()\n",
    "        actual_prices = df['Price'].iloc[train_size:].values\n",
    "        future_dates = df.index[train_size:]\n",
    "\n",
    "        # Evaluation metrics\n",
    "        mae = mean_absolute_error(actual_prices, predictions)\n",
    "        rmse = np.sqrt(mean_squared_error(actual_prices, predictions))\n",
    "        mape = np.mean(np.abs((actual_prices - predictions) / actual_prices)) * 100\n",
    "\n",
    "        print(f\"MAE XGBoost (Optuna): {mae:.4f}\")\n",
    "        print(f\"MAPE XGBoost (Optuna): {mape:.4f}%\")\n",
    "        print(f\"RMSE XGBoost (Optuna): {rmse:.4f}\")\n",
    "\n",
    "        # Plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(df.index[-60:], df['Price'][-60:], label='Actual Prices', marker='o')\n",
    "        plt.plot(future_dates, predictions, label='Predicted Prices (XGBoost)', linestyle='dashed', color='red', marker='o')\n",
    "        plt.legend()\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Price')\n",
    "        plt.title(f'XGBoost Backtesting (Actual vs Predicted - 30 Days) for {name}')\n",
    "\n",
    "        predict_path = \"images/prediction_xgboost.png\"\n",
    "        plt.savefig(predict_path)\n",
    "        plt.close()\n",
    "\n",
    "        execution_time = time.time() - start_time\n",
    "        print(f\"Execution Time: {execution_time:.4f} seconds \\n\")\n",
    "\n",
    "        return predict_path\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradio Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the functions and how they work are implemented into two functions which are:\n",
    "- process_skin_input(): Takes in user inputs and process them \n",
    "- process_case_input(): Does the same thing, just for cases \n",
    "\n",
    "This then is used in conjunction with the gradio interface to make it easier for users to interact with the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://steamcommunity.com/market/listings/730/Gallery%20Case\n",
      "Saved JSON as item.json in the root directory.\n",
      "MAE XGBoost (Optuna): 0.0497\n",
      "MAPE XGBoost (Optuna): 5.7237%\n",
      "RMSE XGBoost (Optuna): 0.0624\n",
      "Execution Time: 6.5876 seconds \n",
      "\n",
      "https://steamcommunity.com/market/listings/730/Dreams%20%26%20Nightmares%20Case\n",
      "Saved JSON as item.json in the root directory.\n",
      "MAE XGBoost (Optuna): 0.0511\n",
      "MAPE XGBoost (Optuna): 2.4021%\n",
      "RMSE XGBoost (Optuna): 0.0654\n",
      "Execution Time: 9.3505 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def process_skin_input(weapon_input, skin_name, condition, modifiers):\n",
    "    url_format = load_skins()  # Load skin list\n",
    "    sr_format = search_list()  # Load search list\n",
    "\n",
    "    search = find_skin(sr_format, url_format, weapon_input, skin_name, condition, modifiers)\n",
    "    \n",
    "    if not search:\n",
    "        return \"Skin not found. Please check your input.\", None, None, None\n",
    "    \n",
    "    img = fetch_item_image(search)\n",
    "\n",
    "    url = create_url(search)\n",
    "    get_json(url, \"item\")  \n",
    "\n",
    "    file_path = \"item.json\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.DataFrame(data[\"prices\"], columns=[\"timestamp\", \"price\", \"volume\"])\n",
    "    df[\"price\"] = df[\"price\"].astype(float)\n",
    "    df[\"volume\"] = df[\"volume\"].astype(int)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%b %d %Y %H: +0\", errors=\"coerce\")\n",
    "    df = df.dropna().sort_values(\"timestamp\")\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x=df[\"timestamp\"], y=df[\"price\"], color=\"b\", label=\"Price\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(f\"Price Over Time for {search}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "\n",
    "    temp_path = \"images/temp_chart.png\"\n",
    "    plt.savefig(temp_path)\n",
    "    plt.close()\n",
    "\n",
    "    return search, img, temp_path, predict_price_xgboost(search)\n",
    "\n",
    "def process_case_input(case_name):\n",
    "    case_data = load_cases()\n",
    "    search = find_case(case_data, case_name)\n",
    "\n",
    "    if not search:\n",
    "        return \"Case not found. Please check your input.\", None, None, None\n",
    "\n",
    "    img = fetch_item_image(search)\n",
    "\n",
    "    url = create_url(search)\n",
    "    get_json(url, \"item\")  \n",
    "\n",
    "    file_path = \"item.json\"\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    df = pd.DataFrame(data[\"prices\"], columns=[\"timestamp\", \"price\", \"volume\"])\n",
    "    df[\"price\"] = df[\"price\"].astype(float)\n",
    "    df[\"volume\"] = df[\"volume\"].astype(int)\n",
    "    df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"], format=\"%b %d %Y %H: +0\", errors=\"coerce\")\n",
    "    df = df.dropna().sort_values(\"timestamp\")\n",
    "\n",
    "    sns.set_style(\"darkgrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.lineplot(x=df[\"timestamp\"], y=df[\"price\"], color=\"b\", label=\"Price\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.title(f\"Price Over Time for {search}\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend()\n",
    "\n",
    "    temp_path = \"images/temp_chart.png\"\n",
    "    plt.savefig(temp_path)\n",
    "    plt.close()\n",
    "\n",
    "    return search, img, temp_path, predict_price_xgboost(search)\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# Counter-Strike Market Analyzer\")\n",
    "    selection = gr.Radio([\"Skins\", \"Case\", \"Knifes and Gloves\"], label=\"Select Item Type [Skins/Case]\", value=None)\n",
    "\n",
    "    with gr.Column(visible=False) as skins_interface: \n",
    "        with gr.Row():\n",
    "            weapon_input = gr.Dropdown(\n",
    "                    ['AK-47', 'AUG', 'AWP', 'CZ75-Auto', 'Desert Eagle', 'Dual Berettas', 'FAMAS', 'Five-SeveN', \n",
    "                    'G3SG1', 'Galil AR', 'Glock-18', 'M249', 'M4A1-S', 'M4A4', 'MAG-7', 'MAC-10', 'MP5-SD', 'MP9', \n",
    "                    'Negev', 'Nova', 'P2000', 'P250', 'P90', 'PP-Bizon', 'R8 Revolver', 'SCAR-20', 'SG 553', \n",
    "                    'SSG 08', 'Sawed-Off', 'Tec-9', 'UMP-45', 'USP-S', 'XM1014', 'Zeus x27'],\n",
    "                    label=\"Select a Weapon\"\n",
    "                )\n",
    "            skin_name = gr.Textbox(label=\"Enter Skin Name: \", placeholder=\"e.g, Dragon Lore\")\n",
    "        with gr.Row():\n",
    "            condition = gr.Dropdown([\"Factory New\", \"Minimal Wear\", \"Field Tested\", \"Well Worn\", \"Battle-Scarred\"], label=\"Condition\")\n",
    "            modifiers = gr.Dropdown([ \"Base\", \"StatTrak\", \"Souvenir\"], label=\"Pick the Modifiers\")\n",
    "        btn1 = gr.Button(\"Submit\")\n",
    "       \n",
    "        text_msg = gr.Textbox(label=\"Result\", interactive=False)\n",
    "        item_image = gr.Image(label=\"Item Image\")\n",
    "        with gr.Row():\n",
    "            priceChart = gr.Image(label=\"Price Trend\")\n",
    "            predictChartXGB = gr.Image(label=\"Price Prediction XGB\")\n",
    "\n",
    "\n",
    "        btn1.click(\n",
    "            fn=process_skin_input,\n",
    "            inputs=[weapon_input, skin_name, condition, modifiers],\n",
    "            outputs=[text_msg, item_image, priceChart, predictChartXGB]\n",
    "        )\n",
    "\n",
    "    with gr.Column(visible=False) as cases_interface:  \n",
    "        case_input = gr.Dropdown(\n",
    "                    [\n",
    "                    \"Gallery Case\", \"Kilowatt Case\", \"Revolution Case\", \"Recoil Case\", \"Dreams & Nightmares Case\",\n",
    "                    \"Chroma 2 Case\", \"Chroma 3 Case\", \"Chroma Case\", \"Clutch Case\", \"CS20 Case\", \"CS:GO Weapon Case\", \n",
    "                    \"CS:GO Weapon Case 2\", \"CS:GO Weapon Case 3\", \"Danger Zone Case\", \"eSports 2013 Case\", \n",
    "                    \"eSports 2013 Winter Case\", \"eSports 2014 Summer Case\", \"Falchion Case\", \"Fracture Case\", \"Gamma 2 Case\", \n",
    "                    \"Gamma Case\", \"Glove Case\", \"Horizon Case\", \"Huntsman Weapon Case\", \"Operation Bravo Case\", \"Operation Breakout Weapon Case\",\n",
    "                    \"Operation Broken Fang Case\", \"Operation Hydra Case\", \"Operation Phoenix Weapon Case\", \"Operation Riptide Case\",\n",
    "                    \"Operation Vanguard Weapon Case\", \"Operation Wildfire Case\", \"Prisma 2 Case\", \"Prisma Case\", \"Revolver Case\",\n",
    "                    \"Shadow Case\", \"Shattered Web Case\", \"Snakebite Case\", \"Spectrum 2 Case\", \"Spectrum Case\", \"Winter Offensive Weapon Case\"\n",
    "                    ],\n",
    "                    label=\"Select a Case\"\n",
    "                )\n",
    "        btn2 = gr.Button(\"Submit\")\n",
    "       \n",
    "        text_msg = gr.Textbox(label=\"Result\", interactive=False)\n",
    "        item_image = gr.Image(label=\"Item Image\")\n",
    "        with gr.Row():\n",
    "            priceChart = gr.Image(label=\"Price Trend\")\n",
    "            predictChartXGB = gr.Image(label=\"Price Prediction XGB\")\n",
    "\n",
    "        btn2.click(\n",
    "            fn=process_case_input,\n",
    "            inputs=[case_input],\n",
    "            outputs=[text_msg, item_image, priceChart, predictChartXGB]\n",
    "        )\n",
    "\n",
    "    with gr.Column(visible=False) as kg_interface:  \n",
    "        with gr.Row():\n",
    "            kg_input = gr.Dropdown(\n",
    "                    [\n",
    "                    \"Bayonet\", \"Bowie Knife\", \"Butterfly Knife\", \"Classic Knife\",\n",
    "                    \"Falchion Knife\", \"Flip Knife\", \"Gut Knife\", \"Huntsman Knife\",\n",
    "                    \"Karambit\", \"Kukri Knife\", \"M9 Bayonet\", \"Navaja Knife\", \"Nomad Knife\",\n",
    "                    \"Paracord Knife\", \"Shadow Daggers\", \"Skeleton Knife\", \"Stiletto Knife\",\n",
    "                    \"Survival Knife\", \"Talon Knife\", \"Ursus Knife\",\n",
    "                    \"Bloodhound Gloves\", \"Broken Fang Gloves\", \"Driver Gloves\", \"Hand Wraps\",\n",
    "                    \"Hydra Gloves\", \"Moto Gloves\", \"Specialist Gloves\", \"Sport Gloves\"\n",
    "                    ],\n",
    "                    label=\"Select a Weapon\"\n",
    "                )\n",
    "            skin_name = gr.Textbox(label=\"Enter Skin Name: \", placeholder=\"e.g, Dragon Lore\")\n",
    "        with gr.Row():\n",
    "            condition = gr.Dropdown([\"Factory New\", \"Minimal Wear\", \"Field Tested\", \"Well Worn\", \"Battle-Scarred\"], label=\"Condition\")\n",
    "            modifiers = gr.Dropdown([\"Base\",\"StatTrak\"], label=\"Pick the Modifiers\")\n",
    "        btn3 = gr.Button(\"Submit\")\n",
    "       \n",
    "        text_msg = gr.Textbox(label=\"Result\", interactive=False)\n",
    "        item_image = gr.Image(label=\"Item Image\")\n",
    "        with gr.Row():\n",
    "            priceChart = gr.Image(label=\"Price Trend\")\n",
    "            predictChartXGB = gr.Image(label=\"Price Prediction XGB\")\n",
    "\n",
    "        btn3.click(\n",
    "            fn=process_skin_input,\n",
    "            inputs=[kg_input, skin_name, condition, modifiers],\n",
    "            outputs=[text_msg, item_image, predictChartXGB]\n",
    "        )\n",
    "\n",
    "\n",
    "    def select_type(selection):\n",
    "        if selection == \"Skins\":\n",
    "            return gr.update(visible=True), gr.update(visible=False), gr.update(visible=False)\n",
    "        elif selection == \"Case\":\n",
    "            return gr.update(visible=False), gr.update(visible=True), gr.update(visible=False)\n",
    "        elif selection == \"Knifes and Gloves\":\n",
    "            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=True)\n",
    "        else:\n",
    "            return gr.update(visible=False), gr.update(visible=False), gr.update(visible=False)\n",
    "\n",
    "\n",
    "    selection.change(\n",
    "        fn=select_type,\n",
    "        inputs=[selection],\n",
    "        outputs=[skins_interface, cases_interface, kg_interface]\n",
    "    )\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
